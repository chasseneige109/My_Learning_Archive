### 상세 과정

- **가정:** 10초짜리 오디오, 샘플링 레이트 16kHz (1초에 16,000개 샘플)
    
- **Input Data:** $1 \times 160,000$ (1차원 벡터)

#### Step 1. Framing (윈도우로 잘게 쪼개기)

소리의 특징은 아주 짧은 시간 동안에는 급격히 변하지 않는다고 가정합니다. 
그래서 데이터를 아주 얇게 썹니다.

- **Window Size (창 크기):** 보통 **25ms**를 봅니다.
    
    - $16,000 \times 0.025 = 400$ 샘플. (한 조각의 크기)
        
- **Hop Size (이동 간격):** 윈도우를 **10ms**씩 옆으로 밀면서 겹쳐서 자릅니다.
    
    - $16,000 \times 0.010 = 160$ 샘플.
        

> 결과: 10초(10,000ms)를 10ms 간격으로 찍었으므로, 약 **1,000개의 조각(Frame)**이 생깁니다.
>
> 이것이 바로 행렬의 세로축(Time, $T$)인 1,000이 됩니다.

#### Step 2. STFT (주파수 분석)

잘라낸 **400개의 샘플(25ms 조각)** 하나하나는 여전히 시간 도메인의 데이터입니다. 이를 **푸리에 변환(FFT)**을 통해 주파수 성분으로 바꿉니다.

- **입력:** 400개의 시간 샘플
    
- **연산:** FFT (Fast Fourier Transform)
    
- **출력:** 보통 512개의 주파수 구간(Frequency Bin)으로 나옵니다. (나이퀴스트 이론 등에 의해 결정됨)
    

이제 우리는 **1,000개의 시간 조각** 각각에 대해 **512개의 주파수 정보**를 갖게 되었습니다.

> **중간 결과 (Linear Spectrogram):** $1000(T) \times 512(F_{linear})$ 행렬

#### Step 3. Mel Filterbank (인간의 귀에 맞게 압축)

$512$개의 주파수 정보는 기계에게는 유용하지만, 인간의 언어를 이해하는 데는 너무 많고 불필요한 정보가 섞여 있습니다.

- **인간의 청각:** 저주파(목소리 등)의 차이는 예민하게 구분하지만, 고주파(잡음 등)의 미세한 차이는 잘 구분하지 못합니다.
    
- **Mel-Scale 변환:** 512개의 주파수 구간을 인간이 잘 듣는 영역 위주로 뭉쳐서 **80개(또는 128개)**의 통(Filterbank)으로 압축합니다.
    

> 최종 연산: $(1000 \times 512)$ 행렬과 $(512 \times 80)$ 필터 행렬을 곱합니다.
> 
> 최종 결과 (Mel-Spectrogram): $1000(T) \times 80(F_{mel})$ 행렬

---

### 3. 최종 산출물: Mel-Spectrogram의 의미

이제 우리는 오디오를 **$1000 \times 80$ 크기의 이미지**처럼 다룰 수 있게 되었습니다.

- **행 ($T=1000$):** 시간의 흐름 (0.00초, 0.01초, 0.02초... 10.00초)
    
- **열 ($F=80$):** 소리의 높낮이 (낮은 음 $\rightarrow$ 높은 음)
    
- **값 (Value):** 해당 시간, 해당 주파수에서의 소리 세기(dB, 데시벨)
    

이 **2차원 행렬(이미지)**이 준비되었기 때문에, 비로소 **Speech Transformer**나 **Conformer** 같은 모델들이 이 데이터를 입력받아 "이 부분은 '아' 소리이고, 저 부분은 '녕' 소리구나"라고 패턴을 인식할 수 있게 되는 것입니다.