커널 개수는 내가 미리 정하는 하이퍼파라미터이고,  
각 커널이 “어떤 패턴(직선, 곡선, 모서리, 질감 등)을 감지할지”는 
알아서 학습함.

CNN 커널의 초기 픽셀값(가중치)은 '랜덤 초기화'로 시작한다.

커널 총 개수가 32개라고하면, 
conv layer에 5x5x3 (RGB)짜리 가중치판이 32개가 옆으로 나란히 있음.

직관적으로 그냥 커널이랑 비슷한 구조를 가진게 비슷한 값이 나오겠지. 라고생각하고있긴함
그걸 ReLU로 더 빨리 결과가나오게한게아닐까 2 1 / 1 2보단 2 0 / 0 2가 더 확실하니


커널은 1층짜리 MLP와 완전히 동일하다

## 예시)

커널은 5 x 5 x 3으로 설정. 주로 5칸짜리 커널을 많이쓰고, 3은 RGB
layer1엔 커널 32개
layer2엔 커널 64개
layer3엔 커널 128개 (점점 복잡한 feature를 표현하려면 커널 수가 많아져야함)
... 로 미리 설정.
또한 모든 커널의 값은 Random으로 설정해놓음.

layer1 입력: 100 x 100 x 3(RGB) 이미지를 받고, zero - padding 해놓음.

layer1 Conv: 5 x 5 x 3 커널 32개가 옆으로 나열되어 있음.
각각의 커널을 100 x 100번 스캔하여 convolution 연산을 함. 이때 3채널이었던 RGB를 가중치와 RGB을 가중합하여 100x 100x1채널로 만들어버림. 이게 layer1의 1번째 커널에서 나온 feature_map.


1차원으로 만들어버림

layer2의 커널64개도 처음엔 랜덤으로 정해진 값이고, 그걸 또 32x32 내적한걸 100번 슬라이딩해서 layer1에서 RGB (3개)를 커널 수(32개)로 만들었듯이 스칼라 feature맵 100x100x(64 커널개수)로 만드나


