커널 개수는 내가 미리 정하는 하이퍼파라미터이고,  
각 커널이 “어떤 패턴(직선, 곡선, 모서리, 질감 등)을 감지할지”는 
알아서 학습함.

CNN 커널의 초기 픽셀값(가중치)은 '랜덤 초기화'로 시작한다.

커널 총 개수가 32개라고하면, 
conv layer에 5x5x3 (RGB)짜리 가중치판이 32개가 옆으로 나란히 있음.

직관적으로 그냥 커널이랑 비슷한 구조를 가진게 비슷한 값이 나오겠지. 라고생각하고있긴함
그걸 ReLU로 더 빨리 결과가나오게한게아닐까 2 1 / 1 2보단 2 0 / 0 2가 더 확실하니


커널은 1층짜리 MLP와 완전히 동일하다

## 예시)

커널은 5 x 5 x 3으로 설정. 주로 5칸짜리 커널을 많이쓰고, 3은 RGB
layer1엔 커널 32개
layer2엔 커널 64개
layer3엔 커널 128개 (점점 복잡한 feature를 표현하려면 커널 수가 많아져야함)
... 로 미리 설정.
또한 모든 커널의 값은 Random으로 설정해놓음.

### layer1 입력
100 x 100 x 3(RGB) 이미지를 받고, zero - padding 해놓음.

### layer1 Conv:
5 x 5 x 3 커널 32개가 옆으로 나열되어 있음.
layer1의 커널1을 한 칸씩 움직이며 100 x 100번 스캔하여 convolution 연산을 함. 이때 100 x 100 x 3채널이었던 RGB이미지를 가중치와 RGB을 가중합하여 100 x 100 x 1채널로 만들어버림. 이게 layer1의 커널1에서 나온 feature_map_1 .

layer1의 커널2를 100 x 100번 스캔하여... 위와 같은 연산을 반복하여 layer1의 커널2에서 나온 feature_map을 만듦.

layer1의 커널 32까지 반복함.

### layer1 :
100 x 100 x 1짜리 feature_map이 커널마다 1개씩 나와서 32개가 생겼다.
이를 100 x 100개의 점 각각에 32개의 feature 값을 준다고 생각하여 100 x 100 x 32 짜리 feature map하나를 만든다.

이를 RELU에 넣어서 음수는 0으로 자르고, 양수는 남긴다.


1차원으로 만들어버림

layer2의 커널64개도 처음엔 랜덤으로 정해진 값이고, 그걸 또 32x32 내적한걸 100번 슬라이딩해서 layer1에서 RGB (3개)를 커널 수(32개)로 만들었듯이 스칼라 feature맵 100x100x(64 커널개수)로 만드나


