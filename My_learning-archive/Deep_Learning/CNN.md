커널 개수는 내가 미리 정하는 하이퍼파라미터이고,  
각 커널이 “어떤 패턴(직선, 곡선, 모서리, 질감 등)을 감지할지”는 
알아서 학습함.

CNN 커널의 초기 픽셀값(가중치)은 '랜덤 초기화'로 시작한다.

커널 총 개수가 32개라고하면, 
conv layer에 5x5x3 (RGB)짜리 가중치판이 32개가 옆으로 나란히 있음.

직관적으로 그냥 커널이랑 비슷한 구조를 가진게 비슷한 값이 나오겠지. 라고생각하고있긴함
그걸 ReLU로 더 빨리 결과가나오게한게아닐까 2 1 / 1 2보단 2 0 / 0 2가 더 확실하니


커널은 1층짜리 MLP와 완전히 동일하다
### Conv Layer는 이렇게 생김:

- 커널 N개 (예: 32개)
- - 비선형성(ReLU)
- → 이 전체가 “레이어 1개”


## 0. 전체 그림 한 방에 보기

일반적인 이미지 CNN 파이프라인은 이렇게 생겼다고 보면 돼:

> **입력 이미지 → 여러 번의 (Conv + ReLU + Pool) → (Flatten) → MLP(FC 층들) → Softmax**

조금 풀면:

1. **입력**: `H × W × C` (예: 100×100×3 RGB)
    
2. **Conv Layer 1**: 커널 N개로 feature map 추출
    
3. **ReLU**: 음수 잘라내고 양수만 통과
    
4. **Pooling (Max Pool)**: 해상도 줄이면서 중요한 값만 남김
    
5. **Conv/ReLU/Pool 반복**: 점점 더 추상적인 특징으로 변환
    
6. **Flatten**: 3D feature map → 1D 벡터
    
7. **Fully Connected(FC) Layer**: 일반 MLP처럼 동작
    
8. **Output (Softmax)**: 각 클래스 확률
    

이제 각 단계를 진짜 세세하게 뜯어보자.