# **Text-to-Text Transfer Transformer 

- BERT(Encoder)와 GPT(Decoder)를 결합

- **"Encoder가 소화시킨 정보를 Decoder가 어떻게 가져다 쓰는가?"**에 있으며, 이를 **크로스 어텐션(Cross-Attention)**