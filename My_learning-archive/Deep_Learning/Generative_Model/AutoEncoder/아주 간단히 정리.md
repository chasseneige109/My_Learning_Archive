나선형을 예시로 하자.

AE는 학습 데이터에 없는 부분을 복원할 때 갑자기 값이 이상한 데로 튐.

-> 이걸 막기위해 '가우스 분포에서 잘 나올법한 결과'를 만들기 위해
Gaussian negative log-likelihood를 최소화하는 (= L2norm 최소화) 역할을 하는
regularization항 추가.

-> 하지만 아직도 Manifold가 우리가 선택한 k 차원 안에 있을 수밖에 없다는 한계.
, manifold의 중심선만 있고, 그 근처의 확률 밀도를 전혀 알 수 없다는 한계.
(같은 사람이라도, 표정이 다르고, 같은 숫자도, 필기체가 다름)

-> 그래서 x(입력)을 만들었을 법한 z(확률분포)를 추정해야함 --> p(z | x)
근데 p(z | x)는 추정하기 매우 힘듦. 따라서 저걸 근사하는 q(z | x)를 대신 구함.
