제시하신 VAE의 두 가지 주요 한계점과 이것이 Normalizing Flow 및 Diffusion Model로 어떻게 이어지는지를 간결하게 정리해 드리겠습니다.

---

### **VAE의 주요 한계와 해결 방향**

#### **1. 한계 ①: Posterior 근사 문제 (The Inference Gap)**

| **문제**    | **원인**                                     | **해결 아이디어 → 모델**                |
| --------- | ------------------------------------------ | ------------------------------- |
| **$P(z    | x)$를 $Q(z                                  | x)$로 근사하는 데서 오는 오차.**           |
| **핵심**    | $Q$와 $P$ 사이의 $\text{KL}$ $\left(D_{KL}(Q(z | x) \| P(z                       |
| **다음 모델** |                                            | **Normalizing Flow** (다음 단계 모델) |

#### **2. 한계 ②: 출력이 "뿌옇다 (Blurry)" 문제**

| **문제**                   | **원인**                                                                            | **해결 아이디어 → 모델**                                                 |
| ------------------------ | --------------------------------------------------------------------------------- | ---------------------------------------------------------------- |
| **샘플 이미지의 품질 저하 (흐릿함).** | 디코더가 **평균적인 이미지**를 생성하는 경향이 있으며, 노이즈를 $\mathcal{N}(0, I)$라는 구조 없는 가우시안으로 가정했기 때문. | **단순한 $P(z)$ Prior를 여러 단계로 점진적으로 복잡하게** 만들어 실제 데이터 분포에 가까워지도록 함. |
| **핵심**                   | $P(z)$ (Prior)가 너무 단순하여, 복잡한 데이터 분포까지 한 번에 도약하기 어려움. $\rightarrow$ 평균적인 해석 초래.    | $\Downarrow$                                                     |
| **다음 모델**                |                                                                                   | **Diffusion Model** (다음 단계 모델)                                   |

VAE는 생성 모델의 중요한 기반을 다졌으나, 위 두 가지 한계를 극복하기 위해 **Normalizing Flow**와 **Diffusion Model**이라는 새로운 방법론이 발전하게 됩니다.