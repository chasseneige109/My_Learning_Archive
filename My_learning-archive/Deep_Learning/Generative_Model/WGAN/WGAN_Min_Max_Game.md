Wasserstein 거리를 Loss Function으로 쓴다는 것은 **"최적화 문제(거리 계산)를 안에 품고 있는 또 다른 최적화 문제(모델 학습)"**를 푼다는 뜻입니다. 이를 **이중 최적화(Bilevel Optimization)** 또는 **Min-Max Game**이라고 부릅니다.

이 구조를 **심판(Critic)**과 **위조지폐범(Generator)**의 관계로 정리하면 아주 명확해집니다.

---

### 1. 구조: 최적화 안에 최적화가 있다

전체 목표는 **생성 모델($G$)의 파라미터 $\theta$를 조절해서 가짜와 진짜의 거리($W$)를 최소화($\min$)하는 것**입니다.

$$\min_{\theta} \underbrace{W(\text{Fake}_{\theta}, \text{Real})}_{\text{Loss Function}}$$

그런데, 저 $W$ 값을 알아내려면(계산하려면) 먼저 내부에서 최적화를 한 번 해야 합니다.

$$\min_{\theta} \left[ \underbrace{\max_{f \in \text{Lipschitz}} \left( \mathbb{E}[f(\text{Real})] - \mathbb{E}[f(\text{Fake}_{\theta})] \right)}_{\text{거리 } W \text{를 계산하는 과정 (Dual)}} \right]$$

_(참고: 계산 편의상 Primal의 $\min \gamma$ 대신 Dual의 $\max f$를 주로 사용합니다.)_

---

### 2. 두 개의 루프 (Two Loops)

그래서 실제 코드를 보면 **for 문이 두 개** 돌아갑니다.

#### 1단계: 거리 측정 (Inner Loop) - "자, 지금 거리가 몇인지 정확히 재보자."

- **주체:** 판별자(Discriminator/Critic)
    
- **목표:** 현재의 가짜와 진짜 사이의 차이($W$)를 **최대로 벌려서(Max)** 정확한 거리를 계산해내는 것.
    
- **행동:** $f$ 함수(판별자)를 학습시킵니다.
    
- **의미:** 님께서 말씀하신 **"Wasserstein 거리를 구하는 문제"**를 푸는 단계입니다.
    

#### 2단계: 거리 줄이기 (Outer Loop) - "거리가 10이네? 그럼 줄이자."

- **주체:** 생성자(Generator)
    
- **목표:** 방금 1단계에서 계산된 거리($W$)가 **작아지도록(Min)** 만드는 것.
    
- **행동:** 생성자의 파라미터 $\theta$를 업데이트합니다 (Gradient Descent).
    
- **의미:** 님께서 말씀하신 **"Loss Function을 최소화하는 문제"**를 푸는 단계입니다.
    

---

### 3. 왜 이게 어려운가? (계산 비용)

우리가 일반적인 딥러닝(예: MSE Loss)을 할 때는 Loss 계산이 그냥 **"뺄셈하고 제곱($y - \hat{y})^2$"**하면 끝나는 단순 산수였습니다.

하지만 Wasserstein Loss를 쓸 때는:

> "Loss 값 하나를 구하기 위해(1단계), **매번 내부에서 별도의 최적화(학습)**를 돌려야 한다"

는 엄청난 부담이 생깁니다.

그래서 WGAN 논문을 보면, **"Generator를 1번 업데이트하기 위해, Discriminator를 5번 반복해서 학습시킨다"**는 내용이 나옵니다.

- 거리를 **정확하게 재야(1단계 최적화 성공)**,
    
- 그 값을 줄이는 **방향도 정확하게 알 수 있기(2단계 최적화 성공)** 때문입니다.
    

### 요약

님의 통찰이 정확합니다.

1. **Inner Problem:** "현재 상태에서 최적의 운송 비용(거리)은 얼마인가?"를 풀어서 **Loss 값을 확정**짓고,
    
2. **Outer Problem:** "그 Loss 값을 줄이려면 내 가중치를 어떻게 바꿔야 하나?"를 풀어서 **학습**을 합니다.
    

이 **Min-Max(최소-최대)** 구조 때문에 학습 균형을 맞추기가 까다롭지만, 성공만 하면 기존 방식보다 훨씬 퀄리티가 좋은 결과를 얻게 됩니다.