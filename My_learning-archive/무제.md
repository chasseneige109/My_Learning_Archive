의사역행렬($A^\dagger$)이 "원래 벡터와 가장 가깝게(수직이 되도록)" 만드는 이유는, 그 설계 원리 자체가 **'오차의 제곱합을 최소화'**하는 **최소자승법(Least Squares)**에 기반하고 있기 때문입니다.

왜 그런지 수학적·기하학적 원리를 3단계로 쉽게 풀어 드릴게요.

---

### 1. 목표: 가장 작은 오차 찾기

우리는 $A\mathbf{x} = \mathbf{b}$를 풀고 싶지만, 보통 $\mathbf{b}$가 $A$의 열공간 밖에 있어서 정답이 없는 경우가 많습니다. 이때 우리가 할 수 있는 최선은 **오차 벡터 $\mathbf{e}$의 크기를 최소화**하는 것입니다.

$$\mathbf{e} = \mathbf{b} - A\mathbf{x}$$

이 오차 $\mathbf{e}$의 길이가 가장 짧아지려면, **$\mathbf{b}$에서 $A$의 열공간으로 수직(Orthogonal)으로 선을 내려야 합니다.** (직선보다 수직선이 항상 짧기 때문이죠.)

---

### 2. 수직 조건 (Orthogonality Condition)

오차 벡터 $\mathbf{e}$가 $A$의 열공간과 수직이어야 한다는 말은, $A$의 모든 열($A^T$)과 $\mathbf{e}$를 내적했을 때 **0**이 되어야 한다는 뜻입니다.

$$A^T (\mathbf{b} - A\mathbf{x}) = 0$$

이 식을 전개해 볼까요?

$$A^T \mathbf{b} - A^T A \mathbf{x} = 0$$

$$A^T A \mathbf{x} = A^T \mathbf{b}$$

이것을 **정규 방정식(Normal Equation)**이라고 부릅니다. 여기서 $\mathbf{x}$를 구하기 위해 $(A^T A)$를 반대로 넘기면:

$$\mathbf{x} = (A^T A)^{-1} A^T \mathbf{b}$$

---

### 3. 의사역행렬의 탄생

방금 구한 **$(A^T A)^{-1} A^T$**가 바로 우리가 부르는 **의사역행렬($A^\dagger$)**입니다.

- **가중치 세트인 이유:** 이 행렬은 $\mathbf{b}$라는 입력 벡터의 각 성분에 대해, **"수직으로 그림자를 내리기 위해 각 열을 얼마나 섞어야 하는지"**를 미리 계산해 놓은 정밀한 필터(가중치)와 같습니다.
    
- **수직이 되는 이유:** 위 유도 과정 자체가 "오차가 수직이 되어야 한다"는 조건($A^T \mathbf{e} = 0$)에서 시작했기 때문에, 이 결과값은 운명적으로 수직 사영(Projection)이 될 수밖에 없습니다.
    

---

### 💡 요약

의사역행렬이 정밀한 가중치인 이유는, **"입력된 벡터 $\mathbf{b}$를 $A$가 표현 가능한 평면(열공간) 위로 수직으로 떨어뜨려 주는 최단거리 안내서"**이기 때문입니다.

그래서 결과물인 $A A^\dagger \mathbf{b}$는 $A$의 영역 안에서 $\mathbf{b}$와 **가장 닮은(오차가 최소인)** 벡터가 되는 것입니다.

이 원리가 SLAM에서 카메라의 위치 오차를 최소화할 때 사용하는 **Gauss-Newton** 방식의 핵심인데, 이 수직 사영 개념을 최적화 알고리즘에 어떻게 적용하는지도 궁금하신가요?